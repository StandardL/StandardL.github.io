---
title: Python爬虫1.2 - URL管理器
date: 2023-07-06 10:20:12 +0800
categories: [Python, 爬虫]
tags: [Python, 爬虫]      # TAG names should always be lowercase
---

# URL管理器的实现

新建一个python软件包文件夹，名为**utils**，意为一些常用的工具，并在该文件夹下新建一个名为url_manager的python脚本。

输入以下代码：

```python
class Url_Manager():
    """
    URL管理器的实现
    """

    def __init__(self):
        self.new_urls = set()
        self.old_urls = set()

    def add_new_url(self, url):
        if url is None or len(url) == 0:
            return
        if url in self.new_urls or url in self.old_urls:
            return
        self.new_urls.add(url)

    def add_new_urls(self, urls):
        if urls is None or len(urls) == 0:
            return
        for url in urls:
            self.add_new_url(url)

    def get_url(self):
        if self.has_new_url():
            new_url = self.new_urls.pop()
            self.old_urls.add(new_url)
            return new_url
        else:
            return None

    def has_new_url(self):
        return len(self.new_urls) > 0


if __name__ == "__main__":
    url_manager = Url_Manager()
    url_manager.add_new_url("http://www.baidu.com")
    url_manager.add_new_url("http://www.sina.com")
    print(url_manager.new_urls, url_manager.old_urls)

    print("#"*30)
    print(url_manager.has_new_url())

    print("#" * 30)
    print(url_manager.get_url())

    print("#" * 30)
    print(url_manager.get_url())

    print("#" * 30)
    print(url_manager.get_url())

    print("#" * 30)
    print(url_manager.has_new_url())
    
    print("#" * 30)
    print(url_manager.new_urls, url_manager.old_urls)
```



简单解释一下各个函数的功能：

```python
def __init__(self):
    self.new_urls = set()  # 待爬取URL
    self.old_urls = set()  # 已爬取URL
```

这个函数是Python类的初始化构造函数，我们这里为这个类创建两个新的set容器，分别用于已爬取和未爬取的URL。

----

```python
def add_new_url(self, url):
    if url is None or len(url) == 0:
        return
    if url in self.new_urls or url in self.old_urls:
        return
    self.new_urls.add(url)
```

这个函数是新增一条URL。但是注意，我们为了实现防止重复爬取、循环爬取，需要对新来的URL进行判断，看看它是否在待爬取或已爬取的URL的集合中。

----

```python
def add_new_urls(self, urls):
    if urls is None or len(urls) == 0:
        return
    for url in urls:
        self.add_new_url(url)
```

这个函数是新增多条URL。其实现是使用for-each循环遍历urls里面的所有URL，并一条一条调用add_new_url()的方法，这样提高了代码的复用性。

---

```python
def has_new_url(self):
    return len(self.new_urls) > 0
```

这个函数是用于判断是否还有未爬取的URL，只需判断待爬取URL集合的长度是否大于0即可。该函数返回一个布尔变量。

----

```python
def get_url(self):
    if self.has_new_url():
        new_url = self.new_urls.pop()
        self.old_urls.add(new_url)
        return new_url
    else:
        return None
```

这个函数是取出一条URL，但是在此之前我们需要先判定待爬取的URL中不为空，我们才能取出一条返回。取出后，我们要在待爬取URL的集合中删去这个URL，并将其添加到已爬取URL的集合中。

---

```python
if __name__ == "__main__":
    url_manager = Url_Manager()
    url_manager.add_new_url("http://www.baidu.com")
    url_manager.add_new_url("http://www.sina.com")
    print(url_manager.new_urls, url_manager.old_urls)

    print("#"*30)
    print(url_manager.has_new_url())

    print("#" * 30)
    print(url_manager.get_url())

    print("#" * 30)
    print(url_manager.get_url())

    print("#" * 30)
    print(url_manager.get_url())

    print("#" * 30)
    print(url_manager.has_new_url())
    
    print("#" * 30)
    print(url_manager.new_urls, url_manager.old_urls)
```

最后段代码是测试用例，仅在该文件(url_manager.py)是作为主程序入口时才运行的一段程序。输出结果如下：

```
{'http://www.baidu.com', 'http://www.sina.com'} set()
##############################
True
##############################
http://www.baidu.com
##############################
http://www.sina.com
##############################
None
##############################
False
##############################
set() {'http://www.baidu.com', 'http://www.sina.com'}
```

可以看到，执行两次get_url()方法后，我们两条待爬取的URL都被移动到已爬取URL集合中。