---
title: Python爬虫1.4 - 探索待爬取的网页
date: 2023-07-14 23:11:00 +0800
categories: [Python, 爬虫]
tags: [Python, 爬虫]      # TAG names should always be lowercase
---

# 探索待爬取的网页

## 为什么需要探索？

对于一个网页，我们只有事先了解过，我们才能得知我们需要的信息在网页的什么位置，从而在爬虫时能够有针对性抓取内容，提高爬虫效率。

## 如何探索？

此处以我的个人blog为例子进行探索。

待爬取网址：standardl.github.io

样式如下：

![image-20230714231529827](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/Blog截图.png)

### 直接查看网页源代码

以Chrome浏览器（包括基于Chromium的浏览器，常见的如新版Microsoft Edge，360浏览器，QQ浏览器等）为例。

我们对着网页空白处使用右键，在打开的右键菜单中就能看到**查看网页源代码**选项：

![image-20230714231802401](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/右键菜单.png)

点击它就能打开一个新的标签页，且URL为：view-source:https://standardl.github.io/

这个URL是Chrome和Chromium浏览器特有的，其在我们访问的页面前加上了`view-source`字样，说明我们正在查看的网页的源代码，且是没有经过JavaScript动态加载的HTML源代码。

### 使用检查查看网页源代码

还是在右键菜单中，我们选择检查选项，或者按下键盘上的<kbd>F12</kbd>，就会跳出来一个新的菜单。此时Edge可能会提示是否打开开发人员菜单，选择是即可。

![image-20230714232414222](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/Edge开发人员菜单确认.png)

打开开发工具后，我们能看见在浏览器的右侧出现了一个新的工具栏。

![image-20230714232704558](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/Edge开发人员菜单.png)

工具栏的样式也许会根据Edge版本，（或Chrome版本，Chromium版本）有所差异，但总体来说，都有以下几种功能：

1. 元素（Elements）
2. 控制台（Console）
3. 源代码（Sources）
4. 网络（Network）
5. 性能（Performance）
6. ...

对于我们爬虫来说，需要重点关注的是元素和源代码。

#### 元素 Elements

这里显示的也是网页的源代码，但是是经过了JavaScript动态加载的、也就是说我们实际在浏览器窗口中显示的网页源代码。

这里有一个很重要的功能是通过Elements定位网页的内容在HTML文件中的位置，我们只需要对着需要抓取的内容右键 - 检查，即可在元素中高亮对应的代码行。比如我要查看我博客LOGO的源代码：

![image-20230714233430079](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/Blog查看头像源代码.png) 

注意高亮的头像和右侧高亮的代码段。

可以看到，我的LOGO在在一个id为avatar的区块内，并且带有指向博客首页的超链接。

#### 网络 Network

网络功能相当于一个内置的抓包软件，可以抓取我们连接到网页服务器的开始到结束这段时间内，从服务器上下载的所有内容。

![image-20230714233937462](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/Blog网络抓包.png)

选择网络选项卡后，手动刷新网页，可以看到加载时间，向服务器中请求的URL以及他们的状态、属性等内容。

下面简单介绍一下常用功能。

1. 保存日志 Preserve log

   勾选后，当我们刷新网页或者跨网页访问时，日志就会得到保留而不会被刷新丢弃。

2. 禁用缓存 Disable cache

   由于我们是爬虫，因此一般需要勾选上这个选项，否则浏览器会读取一些本地缓存来加速网页的显示。特别是像我博客的这种静态网页，如果不勾选的话，很有可能打开的网页是过时的网页，导致我们爬虫的结果和我们实际看到的网页出现不一致的问题。

3. 筛选类型

   访问网页时，浏览器会向网页服务器发送很多请求，包括CSS元素，文档，JavaScript等，一般而言，我们需要筛选文档（Doc）进行查看，因此这里需要选择文档来限定HTML文档。

   ![image-20230714234957459](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/Blog网络抓包-筛选文档.png)

   筛选后，这里仅剩下一份文档。这里点击我们访问的网页主链接，这里又会打开一个新选项卡，大致有标头（Headers），响应（Response）等标签。下面简单介绍一下这两个标签的功能。

   1. 标头 Headers

      显示浏览器向网页服务器发送的请求URL，请求方法，状态代码，User-Agent等信息。

      ![image-20230714235357245](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/Blog网络抓包-筛选文档-标头.png)

      为了在爬虫的时候能够得到我们想要的信息，我们可以记住这里的请求URL和请求方法。状态代码是服务器返回给我们浏览器的代码，200表示成功，其他则表示出现各种异常。

      Content-Type这栏，显示的返回的网页类型是HTML，且字符集为UTF-8。

      往下滚动，看到User-Agent这一栏，也可以记录下来。在默认情况下，我们的Requests爬虫是不带任何User-Agent的，容易被一些网站判定为爬虫而被禁止访问，因此我们可以通过自定义User-Agent，来让网站服务器误以为我们的爬虫程序是一个真人在利用浏览器访问。

      ![image-20230714235619429](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/Blog网络抓包-筛选文档-标头2.png)

      对于一些网页，在请求标头里还有Cookie，这是远程服务器给我们的一个唯一标识符，用于存储用户登录状态，记住密码等功能。

   2. 响应 Response

      ![image-20230715000716208](https://github.com/StandardL/StandardL.github.io/raw/main/assets/img/posts/2023-07-14-Python爬虫1.4/Blog网络抓包-筛选文档-响应.png)

      其显示的内容和我们在方法一中点击查看网页源代码的内容是一模一样的。

