---
title: Python爬虫1.1 - Requests的使用
date: 2023-07-03 17:25:33 +0800
categories: [Python, 爬虫]
tags: [Python, 爬虫]      # TAG names should always be lowercase
---

# Requests的使用

在test的目录下我们新建一个名为“requests的使用”的python脚本，并输入以下代码：

```python
import requests

url = "https://www.baidu.com"

r = requests.get(url)
print(r.status_code)
print(r.headers)
print(r.encoding)
print(r.text)
print(r.cookies)
```

这是一组常用的requests代码，下面逐步分析其返回值。

- r.status_code

  ```
  200
  ```

  表明我们的请求正常返回。

- r.headers

  ```
  {'Cache-Control': 'private, no-cache, no-store, proxy-revalidate, no-transform', 'Connection': 'keep-alive', 'Content-Encoding': 'gzip', 'Content-Type': 'text/html', 'Date': 'Mon, 03 Jul 2023 09:21:51 GMT', 'Last-Modified': 'Mon, 23 Jan 2017 13:24:18 GMT', 'Pragma': 'no-cache', 'Server': 'bfe/1.0.8.18', 'Set-Cookie': 'BDORZ=27315; max-age=86400; domain=.baidu.com; path=/', 'Transfer-Encoding': 'chunked'}
  ```

  注意看，这里的Content-Type字段为text/html，并没有编码，暗示了此次请求的编码是使用默认编码进行解析。

- r.encoding

  ```
  ISO-8859-1
  ```

  使用默认编码

- r.text

  ![image-20230706105029678](D:\Coder\Github Repos\StandardL.github.io\assets\img\posts\2023-07-03-Python爬虫1.1\图片1.png)

  可以看到，该html语言带有大量的乱码文本，进一步验证了我们编码错误的问题。

  但是，我们在前面的`meta`行可以看到，`charset=utf-8`说明该网页的文本编码为UTF-8。

- r.cookies

  ```
  <RequestsCookieJar[<Cookie BDORZ=27315 for .baidu.com/>]>
  ```



下面我们修改编码以正确抓取网页。

```python
# 在刚刚的代码后面加上这几行
r.encoding = 'utf-8'

# 再次查看文本是否能正确解析
print(r.text)
```

得到的结果为：

![image-20230706105141555](D:\Coder\Github Repos\StandardL.github.io\assets\img\posts\2023-07-03-Python爬虫1.1\图片2.png)

可以看到，中文已被正确解析。